import scrapy
from scrapy.selector import Selector
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.firefox.options import Options
from selenium.webdriver.firefox.service import Service as FirefoxService
from webdriver_manager.firefox import GeckoDriverManager


class DartilSpider(scrapy.Spider):
    name = 'easy'
    start_urls = ['https://www.digikala.com/product/dkp-10632768/%DA%AF%D9%88%D8%B4%DB%8C-%D9%85%D9%88%D8%A8%D8%A7%DB%8C%D9%84-%D8%A7%D9%BE%D9%84-%D9%85%D8%AF%D9%84-iphone-13-pro-max-lla-%D8%AA%DA%A9-%D8%B3%DB%8C%D9%85-%DA%A9%D8%A7%D8%B1%D8%AA-%D8%B8%D8%B1%D9%81%DB%8C%D8%AA-128-%DA%AF%DB%8C%DA%AF%D8%A7%D8%A8%D8%A7%DB%8C%D8%AA-%D9%88-%D8%B1%D9%85-6-%DA%AF%DB%8C%DA%AF%D8%A7%D8%A8%D8%A7%DB%8C%D8%AA-%D9%86%D8%A7%D8%AA-%D8%A7%DA%A9%D8%AA%DB%8C%D9%88/']

    def __init__(self, *args, **kwargs):
        super(DartilSpider, self).__init__(*args, **kwargs)

        options = Options()
        options.add_argument("--headless")
        options.add_argument("--window-size=1920,1200")

        self.driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install()), options=options)

    def parse(self, response):
        self.driver.get(response.url)

        # Wait for some time if necessary for the page to load (you might need to customize this)
        self.driver.implicitly_wait(5)

        # Use Scrapy Selector to parse the HTML
        selector = Selector(text=self.driver.page_source)

        # Extract data
        products = selector.css("span.text-h4.ml-1.text-neutral-800::text").get()
        # price_element = selector.find_element_by_css_selector('span[data-testid="price-no-discount"]')
        # price = products.text.strip() if price_element else 'Not found'
        print(products)

        # Extract data
        # products = selector.css("h3::text").getall()

        # # Print or yield the data as needed
        # for product in products:
        #     print(product)

        self.driver.quit()
